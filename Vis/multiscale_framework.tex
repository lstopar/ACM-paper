% \iffalse
% \begin{itemize}
% 	\item Initial state construction (State Identification)
% 	\item Aggregation (State Aggregation)
% 	\item Transition probabililties (Modeling transitions)
% \end{itemize}
% \fi

The key idea underlying StreamStory is to build and visualize an abstraction of the underlying 
dynamics of the system. Our abstraction is based on Markov chains where we represent the dynamics of the data using states and transitions. A key feature of our system is to present this abstraction over \emph{multiple scales}. 
%
%To capture and summarize the dynamics of the system our methodology represents the data
%in a qualitative manner using states and transitions. 
%
%We begin by presenting an overview
%of our multi-scale methodology. 
The four main steps are shown in Figure~\ref{fig:methodology}.
\begin{figure*}[]
	\centering
	\includegraphics[width=\textwidth]{methodology-V3}
	\caption{Overview of the proposed pipeline. (a) We first represent the multivariate time series as a point cloud, where each point in time, the values of the multiple time series are used as coordinates. To illustrate, we show two noisy approximately periodic signals. (b) We extract the typical states of the system, partitioning the space. Here clustering partitions the space into intervals which correspond to the sections of the phase of the signal. (c) This partition is then translated into a Markov chain model, with each state representing a partition cell. (d) The Markov chain model is simplified by aggregating states, giving a multiscale view of the system.   }
	\label{fig:methodology}
\end{figure*}
%
We begin by considering the multivariate time series as a point cloud in high dimensional space (Fig.~\ref{fig:methodology}(a)), ignoring the time component. The next step identifies the underlying structure of this point cloud, finding the most typical states (Fig.~\ref{fig:methodology}(b)). This is done by considering a metric on the data points and clustering them (Section~\ref{sec:multiscale-implementation}). In Figure~\ref{fig:methodology}, we see two noisy periodic signals which are partitioned roughly according to the phase of the system. 
Each cluster is then associated to a state in a Markov model (Fig.~\ref{fig:methodology}(c)). We refer to these as the \emph{initial states}. 
The dynamics are then modeled through the transition probabilities between the states using continuous time Markov chains. Finally, we construct a hierarchy of such Markov chains by aggregating the initial states into coarser states (Fig.~\ref{fig:methodology}(d)). Each level of the hierarchy is associated to a unique scale, yielding a multi-scale model.

%The methodology starts in the top left part of the figure with an initial step that summarizes
%the structure of the data by identifying their most typical states. It achieves this by \lstopar{placing}
%the data in a \lstopar{design time} metric space and partitioning them. It then associates
%each partition with a single state.
% \lstopar{
% \begin{itemize}
% 	\item These states are used as the lowest-level states.
% \end{itemize}
% }
%In the second step we summarize dynamics by modeling transition probabilities using continuous time Markov chain framework presented in Section \ref{sec:preliminaries}.
% The third and final step aggregates states and transitions into a hierarchy, associating each
% level of the hierarchy with a unique scale, thus providing a multi-scale model. These steps 
% are explained in detail in the following subsections.


% \subsection{Initial State Construction}
% \label{sec:framework-states}

% To construct the initial states, we define a partition function $\lstopar{f}: \mathbb{R}^d \rightarrow I$ mapping the $d$-dimensional signal to a finite, discrete set $I$. These represent the states which represent the basic unit of abstraction in our visualization. To complete the construction of the continuous-time Markov chain, we must define the transition rates.

%The first step in our methodology is the construction of initial lowest level states. Using the notation
%from Section \ref{sec:preliminaries} we define a partition function 
%from $\lstopar{f}: \mathbb{R}^d \rightarrow I$ mapping the $d$-dimensional signal to lowest level states
% \lstopar{
% with the following properties:
% \begin{itemize}
% 	\item similar points in $\mathbb{R}^d$ should be mapped to the same or neighboring partitions.
% \end{itemize} 
% }

%\subsection{Modeling Transition Probabilities}
%\label{sec:framework-transitions}

%While we represent the states as described in Section \ref{sec:framework-states},
Recall that all the data needed to represent a continuous-time Markov chain
is stored as transition rates in a transition rate matrix $Q \in \mathbb{R}^{n \times n}$, where $n$ represents
the cardinality of the finite state space $I$. The initial state space is determined by the  partition function $g$.

Early user feedback showed that transition rates are not very informative for visualizing state transitions. Instead, 
we chose to visualize transitions in terms of the jump chain $\Pi$.
This represents an alternative, but equivalent, representation of a Markov chain by its jump chain and holding times. 

The jump chain of a continuous time Markov chain $(X_t)_{t \ge 0}$ is
a discrete time Markov chain $(Y_n)_{n \ge 0}$ with transition matrix $\Pi$ defined as
\begin{equation}
	\nonumber
	\left(\Pi\right)_{ij} = 
		\left\{
			\begin{array}{ll}
				-\frac{q_{ij}}{q_{ii}} & \mbox{if } i \ne j, q_{ii} \ne 0 \\
				0 & \mbox{if } i \ne j, q_{ii} = 0
			\end{array}
		\right.
\end{equation}
\begin{equation}
	\nonumber
	\left(\Pi\right)_{ii} = 
		\left\{
			\begin{array}{ll}
				0 & \mbox{if } q_{ii} \ne 0 \\
				1 & \mbox{if } q_{ii} = 0
			\end{array}
		\right.
\end{equation}

The formal definition of a Markov chain in terms of its jump chain and holding times is given below.
\begin{defn}
	\label{def:jump-chain-holding-times}
	A right-continuous process $(X_t)_{t \ge 0}$ is a continuous time Markov chain with initial
	distribution $\lambda$ and transition rate matrix $Q$ if its jump chain $(Y_n)_{n \ge 0}$ is a 
	discrete time Markov chain with initial distribution $\lambda$ and transition matrix $\Pi$ and
	for each $n \ge 1$, conditional on $Y_0, Y_1, ..., Y_{n-1}$, its holding times $S_1, S_2, ..., S_{n-1}$
	are independent exponentially distributed random variables of parameters $q_{Y_0}, q_{Y_1}, ..., q_{Y_{n-1}}$
	where $q_i = -q_{ii}$.
\end{defn}

The states and jump matrix define a directed graph which we use to visualize the system. The widths of the arrows represent the corresponding values of the jump matrix. This only encodes the state transitions. To visualize how long the system stays in a state, we use the size of the state.
To determine the size of each state, we use the ergodic properties of $(X_t)_{t \ge 0}$. Specifically,
we use the elements of the stationary distribution $\pi = (\pi_1, \pi_2, ..., \pi_n)$ and draw the area of
state $i$ proportional to $\pi_i$. %We note that under the assumptions presented in Section \ref{sec:preliminaries}
%this distribution always exists. 
We provide an additional visualization, using a \emph{tooltip} to show the holding time or how long the system stays in a state upon arrival, rather than the time spent in the state overall.
% , computed as
% \begin{equation}
% 	\nonumber E(T_i) = \frac{1}{q_i}
% \end{equation}
% where $T_i$ is the $i$-th states' holding time.


\subsection{Aggregation}
\label{sec:framework-aggregation}

We visualize the system at multiple scales  representing
the data at different detail levels - from the finest to the coarsest. To build our multi-scale representation we take as input, the continuous time Markov chain we initially constructed. 

%Recall from Section \ref{sec:preliminaries}, rather than constructing a single partition of our space, we can construct a hierarchical partition. With this hierarchical partition,  each scale $s$ is associated with a specific partition
%function $\lstopar{f_s}: \mathbb{R}^d \rightarrow \lstopar{I_s}$. At the finest scale, we use the partition function \lstopar{$f: \mathbb{R}^d \rightarrow I$}, defined above, inducing state space $I$ of Markov chain $(X_t)_{t \ge 0}$. 
%We then compute \lstopar{$f_s$} by aggregating elements of $I$ using mapping \lstopar{(projection?, parition?)} $\phi_s: I \rightarrow I_s$ and representing \lstopar{$f_s$} as a composition $\lstopar{f_s} = \lstopar{f} \circ \phi_s$. \textcolor{red}{$\phi_s$ is defined using $P_{\phi_s}$} 
%\lstopar{
%\begin{itemize}
%	\item now we have defined everything we need to calcualte the new Markov chain $(X_t^s)_{t \ge 0}$: $f$ and $\phi_s$ and $(X_t)_{t \ge 0}$
%\end{itemize}
%}

We begin with the Markov chain $(X_t)_{t \ge 0}$, generated by the initial partition function $g$. We then aggregate states until only one state remains -- this represents the coarsest possible representation of our system. The aggregation can be defined on the partitions of the space or directly on the states. We describe two strategies for computing the aggregation in Section~\ref{sec:state-aggregation-impl}. We assume we are given $\phi_s: I\rightarrow I_s$, where $I$ is the initial state space and $I_s$ is a coarser partition, which we refer to as scale $s$. 

The cardinality of $I_s$ gives us the state space of our new Markov chain, $(X_t^{s})_{t \ge 0}$. Since a Markov chain is completely specified by a transition rate matrix, the map between Markov chains is a linear map between matrices: 
$$\Phi_s: \mathbb{R}^{n \times n} \rightarrow \mathbb{R}^{m \times m} \quad \mbox{where} \quad m = |I| \leq n =|I_s|$$
To compute this matrix , we adapt the formula proposed in \cite{5746509} to continuous time Markov chains (see Eq. 9 in \cite{5746509}). The function $\Phi_s$ can be expressed as:
\begin{equation}
	\label{eq:ctmc-state-aggregation}
	\Phi_s(Q) = (P_{\phi_s}' \Pi P_{\phi_s})^{-1} P_{\phi_s}' \Pi Q P_{\phi_s}
\end{equation}
where $\Pi = diag(\pi)$, $\pi$ is the stationary distribution of $(X_t)_{t \ge 0}$ and $P_{\phi_s}$ is a 
$n \times m$ matrix with elements
\begin{equation}
	\nonumber
	\left(P_{\phi_s}\right)_{ij} = 
		\left\{
			\begin{array}{ll}
				1 & \mbox{if } \phi_s(i) = j \\
				0 & \mbox{otherwise}.
			\end{array}
		\right.
\end{equation}
%
%We then compute the partition function $f_s: \mathbb{R}^d \rightarrow I_s$ for coarser scales by aggregating elements of $I$, \lstopar{inducing} state space $I_s$. Thus $I_s$ represents a partition of $I$ and can again be used as the state space on scale $s$. $I_s$ is determined by a map $\phi_s: I \rightarrow I_s$. This way $f_s$, can be represented as \lstopar{$f_s = f \circ \phi_s$}.
%
%The details of how compute $\lstopar{f}$ and $\phi_s$ are described in Section~\ref{}. Therefore, the problem is given $I$, $I_s$, $f$ and the Markov chain induced by $I$, to compute the Markov chain induced by $I_s$.
%
%Therefore given $\lstopar{f}$ and $\phi_s$ we have all the information to construct a new Markov chain $(X_t^{(s)})_{t \ge 0}$, induced by state space $I_s$. All that remains is to compute the corresponding transition rate matrix $Q^{(s)}$. To do so, we adapt the formula proposed in \cite{5746509} to continuous time Markov chains. We define function $\Phi_s: \mathbb{R}^{n \times n} \rightarrow \mathbb{R}^{m \times m}$ with $m \le n$ using formula~\ref{eq:ctmc-state-aggregation}.
%
%The states of this new Markov chain $(X_t^{(s)})_{t \ge 0}$ are induced by $I_s$, what remains is to compute the corresponding  transition rate matrix $Q^{(s)}$. To compute $Q^{(s)}$, we adapt the formula proposed in \cite{5746509} to continuous time Markov chains. We define function $\Phi_s: \mathbb{R}^{n \times n} \rightarrow \mathbb{R}^{m \times m}$ with $m \le n$ using formula~\ref{eq:ctmc-state-aggregation}.
%\begin{equation}
%	\label{eq:ctmc-state-aggregation}
%	\Phi_s(Q) = (P_{\phi_s}' \Pi P_{\phi_s})^{-1} P_{\phi_s}' \Pi Q P_{\phi_s}
%\end{equation}
%where $\Pi = diag(\pi)$, $\pi$ is the stationary distribution of $(X_t)_{t \ge 0}$ and $P_{\phi_s}$ is a 
%$n \times m$ matrix with elements
%\begin{equation}
%	\nonumber
%	\left(P_{\phi_s}\right)_{ij} = 
%		\left\{
%			\begin{array}{ll}
%				1 & \mbox{if } \phi_s(i) = j \\
%				0 & \mbox{otherwise}.
%			\end{array}
%		\right.
%\end{equation}
Thus the data needed to represent a Markov chain at a specific scale $s$ is obtained as $Q^{(s)} = \Phi_s(Q)$.
If we define $\psi_s = \phi_s^{-1} \circ \phi_s$, then Equation \ref{eq:ctmc-state-aggregation} can be rewritten as
\begin{equation}
	\label{eq:ctmc-aggregation-alternative}
	q_{\phi_s(i)\phi_s(j)}^{(s)} = \frac{\sum_{k \in \psi_s(i)}\pi_k \sum_{l \in \psi_s(j)} q_{kl}}{\sum_{k \in \psi_s(i)}\pi_k}
\end{equation}
$\pi^{(s)}$, the stationary distribution of $(X_t^{s})_{t \ge 0}$, can be computed directly from
the stationary distribution of the original chain $(X_t)_{t \ge 0}$ by the following rule:
\begin{equation}
	\nonumber
	\pi^{(s)} = \pi P_{\phi_s}.
\end{equation}
Intuitively, the stationary distributions are preserved through the scales, although the intermediate dynamics may change. The amount of change depends on how we construct our hierarchy. This approach is much faster to compute than computing the distribution at each scale individually.

%\primoz{why not just recompute - we need a sentence here} \lstopar{ - it's slower, you need an iterative procedure to compute the stationary distribution}
