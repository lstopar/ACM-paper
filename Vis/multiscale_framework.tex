\begin{itemize}
	\item Initial state construction (State Identification)
	\item Aggregation (State Aggregation)
	\item Transition probabililties (Modeling transitions)
\end{itemize}

We begin this section with an overview of our multi-level visualization methodology. The methodology
consists of three main steps: initial state construction, state aggregation and modeling transition
probabilities.

\subsection{Initial State Construction}
\label{sec:framework-states}

The first step in our methodology is the construction of initial lowest level states. Using the notation
from Section \ref{sec:preliminaries} we define a partition function 
from $\lstopar{f}: \mathbb{R}^d \rightarrow I$ mapping the $d$-dimensional signal to lowest level states
\lstopar{
with the following properties:
\begin{itemize}
	\item similar points in $\mathbb{R}^d$ should be mapped to the same or neighboring partitions.
\end{itemize} 
}

\subsection{Modeling Transition Probabilities}

To capture and visualize the dynamics of the system our methodology represents the data in a qualitative manner
using states and transitions while we represent the states as described in Section \ref{sec:framework-states},
to model transitions we use the continuous-time Markov chain (CTMC) framework.
As mentioned in Section \ref{sec:preliminaries} all the data needed to represent a continuous-time Markov chain
is stored as transition rates in a transition rate matrix $Q \in \mathbb{R}^{n \times n}$. However, initial user
feedback showed transition rates are not a very informative way of visualizing state transitions. Therefore
we choose to visualize transitions in terms of the jump chain $\Pi$.
We note that an alternative way of representing a Markov chain $(X_t)_{t \ge 0}$ with transition rate matrix $Q$
is by its jump chain and holding times. The jump chain of a continuous time Markov chain $(X_t)_{t \ge 0}$ is
a discrete time Markov chain $(Y_n)_{n \ge 0}$ with jump matrix $\Pi$ defined as
\begin{equation}
	\nonumber
	\left(\Pi\right)_{ij} = 
		\left\{
			\begin{array}{ll}
				-\frac{q_{ij}}{q_{ii}} & \mbox{if } i \ne j, q_{ii} \ne 0 \\
				0 & \mbox{if } i \ne j, q_{ii} = 0
			\end{array}
		\right.
\end{equation}
\begin{equation}
	\nonumber
	\left(\Pi\right)_{ii} = 
		\left\{
			\begin{array}{ll}
				0 & \mbox{if } q_{ii} \ne 0 \\
				1 & \mbox{if } q_{ii} = 0
			\end{array}
		\right.
\end{equation}
Theorem \ref{def:jump-chain-holding-times} provides a definition of a Markov chain in terms of its jump chain and holding times.

\begin{defn}
	\label{def:jump-chain-holding-times}
	A minimal right-continuous process $(X_t)_{t \ge 0}$ is a continuous time Markov chain with initial
	distribution $\lambda$ and transition rate matrix $Q$ if its jump chain $(Y_n)_{n \ge 0}$ is a 
	discrete time Markov chain with initial distribution $\lambda$ and transition matrix $\Pi$ and
	for each $n \ge 1$, conditional on $Y_0, Y_1, ..., Y_{n-1}$, its holding times $S_1, S_2, ..., S_{n-1}$
	are independent exponentially distributed random variables of parameters $q_{Y_0}, q_{Y_1}, ..., q_{Y_{n-1}}$
	where $q_i = -q_{ii}$.
\end{defn}

\subsection{Aggregation}

Once we have computed the lowest level Markov chain $(X_t)_{t \ge 0}$, we need to be able to represent it on multiple scales.
As stated in Section \ref{sec:preliminaries} we associate each scale $s$ with a specific partition function
$\lstopar{f_s}: \mathbb{R}^d \rightarrow \lstopar{I_s}$ where coarser partitions are generated by merging 
states of finer partitions.
Suppose we have already computed the finest level partition $\lstopar{\cP}$, inducing state space $I$ and the
coarser partition at scale $\lstopar{\cP_s}$, inducing state space $J$. Suppose the finest level Markov chain,
on state space $I$ is represented by a transition rate matrix $Q$ and define a surjective partition function
$\phi: I \rightarrow J$. To compute the Markov chain induced by state space $J$, we adapt a formula proposed
in \cite{5746509} to continuous time Markov chains. We define a \lstopar{transition rate matrix transformation function}
$\Phi: \mathbb{R}^{n \times n} \rightarrow \mathbb{R}^{m \times m}$ using formula \ref{eq:ctmc-state-aggregation}.
\begin{equation}
	\label{eq:ctmc-state-aggregation}
	\Phi(Q) = \tilde{Q} = (P' \Pi P)^{-1} P' \Pi Q P
\end{equation}
where $\Pi = diag(\pi)$ and $\pi = (\pi_1, \pi_2, ..., \pi_n)$ is the stationary distribution of $(X_t)_{t \ge 0}$, while $P$ is a 
$|I| \times |J|$ partition matrix with elements
\begin{equation}
	\nonumber
	\left(P\right)_{ij} = 
		\left\{
			\begin{array}{ll}
				1 & \mbox{if } \phi(i) = j \\
				0 & \mbox{otherwise}.
			\end{array}
		\right.
\end{equation}
If we define $\psi = \phi \circ \phi$, then Equation \ref{eq:ctmc-state-aggregation} can be rewritten as
\begin{equation}
	\nonumber
	\tilde{q}_{\phi(i)\phi(j)} = \frac{\sum\limits_{i \in \psi(i)}\pi_i \sum\limits_{j \in \psi(j)} q_{ij}}{\sum\limits_{i \in \psi(i)}\pi_i}
\end{equation}